{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from stanfordnlp.server import CoreNLPClient\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPOSITION = \"NP=n1 < (NP=n2 $.. (/,/ $.. NP=n3))\"\n",
    "# def getAppositions(text):\n",
    "#     url = \"http://localhost:9000/tregex\"\n",
    "#     request_params = {\"pattern\": APPOSITION}\n",
    "#     r = requests.post(url, data=text, params=request_params, timeout = 600000)\n",
    "#     js = r.json()\n",
    "#     if js['sentences'][0] and '0' in js['sentences'][0] and 'namedNodes' in js['sentences'][0]['0']:\n",
    "#         return js['sentences'][0]['0']['namedNodes']\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = 'Harry Potter, a young boy, is very famous in US.'\n",
    "# # testTree = getParserTree(text)\n",
    "# ares = getAppositions(text)\n",
    "# ares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NP_VP = \"S < (NP=np $.. (VP=vp < /VB.?/=tensed))\"\n",
    "# def getNP_VP(text):\n",
    "#     url = \"http://localhost:9000/tregex\"\n",
    "#     request_params = {\"pattern\": NP_VP}\n",
    "#     r = requests.post(url, data=text, params=request_params)\n",
    "#     js = r.json()\n",
    "#     if js['sentences'][0] and '0' in js['sentences'][0] and 'namedNodes' in js['sentences'][0]['0']:\n",
    "#         return js['sentences'][0]['0']['namedNodes']\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nres = getNP_VP(text)\n",
    "# nres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctext = \"昨天晚上10点钟，他乘坐出租车回家了。\"\n",
    "# ctext = \"WINDOWS自带的截图工具名称就是“截图工具”，截图多少张都可以，没有专门的文件夹存放截取的图片，需要在截取图片后选择存放位置\"\n",
    "ctext = \"公民申请普通护照，应当由本人向其户籍所在地县级以上地方人民政府公安机关出入境管理机构提出，并提交以上真实有效的材料。\"\n",
    "ctregex = \"IP<(NP=np $.. VP=vp)\"\n",
    "cres = requests.post(\"http://localhost:9000/tregex\", data=ctext.encode('utf8'), params = {\"pattern\": ctregex, \"pipelineLanguage\": \"zh\"},\n",
    "                     timeout = 60\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentences'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cres.json().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['match', 'namedNodes'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cres.json()['sentences'][0]['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'np': '(NP (NN 公民))\\r\\n'},\n",
       " {'vp': '(VP\\r\\n  (VP\\r\\n    (VP (VV 申请)\\r\\n      (NP\\r\\n        (ADJP (JJ 普通))\\r\\n        (NP (NN 护照))))\\r\\n    (PU ，)\\r\\n    (VP (VV 应当)\\r\\n      (VP\\r\\n        (PP (P 由)\\r\\n          (NP (PN 本人)))\\r\\n        (PP (P 向)\\r\\n          (NP (PN 其) (NN 户籍)))\\r\\n        (VP (VV 所在)\\r\\n          (NP\\r\\n            (LCP\\r\\n              (NP (NN 地县级))\\r\\n              (LC 以上))\\r\\n            (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构)))\\r\\n          (IP\\r\\n            (VP (VV 提出)))))))\\r\\n  (PU ，)\\r\\n  (CC 并)\\r\\n  (VP (VV 提交)\\r\\n    (NP\\r\\n      (LCP (LC 以上))\\r\\n      (CP\\r\\n        (IP\\r\\n          (VP\\r\\n            (VCD (VA 真实) (VA 有效))))\\r\\n        (DEC 的))\\r\\n      (NP (NN 材料)))))\\r\\n'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cres.json()['sentences'][0]['0']['namedNodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentences': [{'0': {'match': '(IP\\r\\n  (NP (NN 公民))\\r\\n  (VP\\r\\n    (VP\\r\\n      (VP (VV 申请)\\r\\n        (NP\\r\\n          (ADJP (JJ 普通))\\r\\n          (NP (NN 护照))))\\r\\n      (PU ，)\\r\\n      (VP (VV 应当)\\r\\n        (VP\\r\\n          (PP (P 由)\\r\\n            (NP (PN 本人)))\\r\\n          (PP (P 向)\\r\\n            (NP (PN 其) (NN 户籍)))\\r\\n          (VP (VV 所在)\\r\\n            (NP\\r\\n              (LCP\\r\\n                (NP (NN 地县级))\\r\\n                (LC 以上))\\r\\n              (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构)))\\r\\n            (IP\\r\\n              (VP (VV 提出)))))))\\r\\n    (PU ，)\\r\\n    (CC 并)\\r\\n    (VP (VV 提交)\\r\\n      (NP\\r\\n        (LCP (LC 以上))\\r\\n        (CP\\r\\n          (IP\\r\\n            (VP\\r\\n              (VCD (VA 真实) (VA 有效))))\\r\\n          (DEC 的))\\r\\n        (NP (NN 材料))))))\\r\\n',\n",
       "    'namedNodes': [{'np': '(NP (NN 公民))\\r\\n'},\n",
       "     {'vp': '(VP\\r\\n  (VP\\r\\n    (VP (VV 申请)\\r\\n      (NP\\r\\n        (ADJP (JJ 普通))\\r\\n        (NP (NN 护照))))\\r\\n    (PU ，)\\r\\n    (VP (VV 应当)\\r\\n      (VP\\r\\n        (PP (P 由)\\r\\n          (NP (PN 本人)))\\r\\n        (PP (P 向)\\r\\n          (NP (PN 其) (NN 户籍)))\\r\\n        (VP (VV 所在)\\r\\n          (NP\\r\\n            (LCP\\r\\n              (NP (NN 地县级))\\r\\n              (LC 以上))\\r\\n            (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构)))\\r\\n          (IP\\r\\n            (VP (VV 提出)))))))\\r\\n  (PU ，)\\r\\n  (CC 并)\\r\\n  (VP (VV 提交)\\r\\n    (NP\\r\\n      (LCP (LC 以上))\\r\\n      (CP\\r\\n        (IP\\r\\n          (VP\\r\\n            (VCD (VA 真实) (VA 有效))))\\r\\n        (DEC 的))\\r\\n      (NP (NN 材料)))))\\r\\n'}]}}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cres.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(NP (NN 公民))\\r\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cres.json()['sentences'][0]['0']['namedNodes'][0]['np']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"公民申请普通护照，应当由本人向其户籍所在地县级以上地方人民政府公安机关出入境管理机构提出，并提交以上真实有效的材料。现役军人按照管理权限履行报批手续后，由本人向所属部队驻地县级以上地方人民政府公安机关出入境管理机构提出。\"\n",
    "text = \"何洛洛在群访中回应称自己一定是会去高考的，虽然今年错过了，但明年一定会全力以赴。何洛洛坦言每个人在追梦的道路上都有自己的选择和机会，他会对自己的选择全力以赴坚持到底。至于错过今年高考是否遗憾，何洛洛给出了否定的答案，“每个人都有自己的选择，既然选择了《创造营2019》，那我明年继续备战高考。”\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NLP分析\n",
    "url = \"http://localhost:9000\"\n",
    "properties = {\"annotators\": \"tokenize,ssplit,pos,ner\",\n",
    "              \"pipelineLanguage\":\"zh\",\n",
    "              \"ssplit.boundaryTokenRegex\": \"[.。]|[!?！？]\"\n",
    "              \"\"\n",
    "             }\n",
    "res = requests.post(url, data=text.encode('utf8'), params = {\"properties\": str(properties)}, timeout = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentences'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = res_dict[\"sentences\"]\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'entitymentions', 'tokens'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1 = sentences[0]\n",
    "sen1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen1[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1_text = ''.join([token['word'] for token in sen1['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'何洛洛在群访中回应称自己一定是会去高考的，虽然今年错过了，但明年一定会全力以赴。'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen1_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreServerAnn(object):\n",
    "    def __init__(self, text, comefrom = None):\n",
    "        self.text = text\n",
    "        self.source_sens = []\n",
    "        self.derived_sens = []\n",
    "        self.comefrom = comefrom\n",
    "    \n",
    "\n",
    "class CoreServerSen(object):\n",
    "    def __init__(self, sen_dict, comefrom = None):\n",
    "        self.sen_dict = sen_dict\n",
    "        self.tokens = self.sen_dict['tokens']\n",
    "        self.words = self._get_words(self.tokens)\n",
    "        self.text = self._get_text(self.tokens)\n",
    "        self.comefrom = comefrom\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sen_dict['tokens'])\n",
    "    \n",
    "    def _get_text(self, tokens):\n",
    "        return \"\".join(token[\"word\"] for token in tokens)\n",
    "    \n",
    "    def _get_words(self, tokens):\n",
    "        return [token[\"word\"] for token in tokens]\n",
    "\n",
    "        \n",
    "class CoreServerAnalyzer(object):\n",
    "    def __init__(self, url = 'http://localhost:9000',\n",
    "                 properties = None,\n",
    "                 lang = \"zh\",\n",
    "                 timeout = 60\n",
    "                ):\n",
    "        self.url = url\n",
    "        self.timeout = timeout\n",
    "        self.lang = lang\n",
    "        self.timeout = timeout\n",
    "        if properties is None:\n",
    "            properties = {\"annotators\": \"tokenize,ssplit,pos,ner,parse\",\n",
    "                          \"ssplit.boundaryTokenRegex\": \"[.。]|[!?！？]\",\n",
    "                          \"pipelineLanguage\": self.lang\n",
    "                         }\n",
    "        self.properties = properties\n",
    "    \n",
    "    def __call__(self, ann, comefrom = None):\n",
    "        if comefrom is None:\n",
    "            comefrom = ann\n",
    "        resp = requests.post(self.url, data=ann.text.encode('utf8'), params = {\"properties\": str(properties)},\n",
    "                             timeout = self.timeout\n",
    "                            )\n",
    "        ann.source_sens = [CoreServerSen(sen_dict, comefrom) for sen_dict in resp.json()['sentences']]\n",
    "        return ann\n",
    "\n",
    "# class CoreServerTreeNode(object):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "# class CoreServerTree(object):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     @classmethod\n",
    "#     def from_str(cls, str):\n",
    "#         pass\n",
    "\n",
    "\n",
    "class CoreServerTranformer(object):\n",
    "    def __init__(self, max_len = None, by_punc = True, rule = None,\n",
    "                 url = \"http://localhost:9000/tregex\", lang = 'zh',\n",
    "                 timeout = 60,\n",
    "                 post_min_len = None,\n",
    "                 post_by_ner = False\n",
    "                ):\n",
    "        self.max_len = max_len\n",
    "        self.by_punc = by_punc\n",
    "        self.puncs = ['?!？！']\n",
    "        self.rule = rule\n",
    "        self.lang = lang\n",
    "        self.properties = {\"pipelineLanguage\": self.lang}\n",
    "        self.url = url\n",
    "        self.timeout = timeout\n",
    "        self.analyzer = CoreServerAnalyzer()\n",
    "        self.post_min_len = post_min_len\n",
    "        self.post_by_ner = post_by_ner\n",
    "        \n",
    "    def __call__(self, ann):\n",
    "        source_sens = ann.source_sens\n",
    "        kept_sens = self._filter(source_sens)\n",
    "        simplified_sens = self._simplify(kept_sens)\n",
    "        derived_sens = self._post_filter(simplified_sens)\n",
    "        ann.derived_sens = derived_sens\n",
    "        return ann\n",
    "        \n",
    "    def _filter(self, source_sens):\n",
    "        kept_sens = source_sens\n",
    "        if self.max_len is not None:\n",
    "            kept_sens = self._filter_by_len(kept_sens)\n",
    "        if self.by_punc:\n",
    "            kept_sens = self._filter_by_punc(kept_sens)\n",
    "        return kept_sens\n",
    "        \n",
    "    def _filter_by_len(self, sens):\n",
    "        kept_sens = [sen for sen in sens if len(sen) <= self.max_len]\n",
    "        return kept_sens\n",
    "    \n",
    "    def _filter_by_punc(self, sens):\n",
    "        kept_sens = [sen for sen in sens if sen.words[-1].strip() not in self.puncs]\n",
    "        return kept_sens\n",
    "    \n",
    "    def _simplify(self, kept_sens):\n",
    "        simplified_sens = []\n",
    "        for sen in kept_sens:\n",
    "            res = requests.post(self.url, data=sen.text.encode(\"utf8\"), params = {\"pattern\": self.rule, \"properties\": str(self.properties)},\n",
    "                                timeout = self.timeout\n",
    "                               )\n",
    "            res_dict = res.json()\n",
    "            sub_sens = res_dict['sentences'][0]\n",
    "            for sub_k, sub_v in sub_sens.items():\n",
    "                    sub_treestr = sub_v[\"match\"]\n",
    "                    sub_text = self._treestr2text(sub_treestr)\n",
    "                    tmp_ann = CoreServerAnn(sub_text)\n",
    "                    tmp_ann = self.analyzer(tmp_ann, sen)\n",
    "                    simplified_sens += tmp_ann.source_sens\n",
    "        return simplified_sens\n",
    "    \n",
    "    def _treestr2text(self, treestr):\n",
    "        pattern = r'[^\\(\\s\\)]+\\)'\n",
    "        words_ = re.findall(pattern, treestr)\n",
    "        words = [w_[:-1] for w_ in words_]\n",
    "        text = \"\".join(words)\n",
    "        return text\n",
    "    \n",
    "    def _post_filter(self, simplified_sens):\n",
    "        kept_sens = simplified_sens\n",
    "        if self.post_min_len is not None:\n",
    "            kept_sens = self._post_filter_by_len(kept_sens)\n",
    "        if self.post_by_ner:\n",
    "            kept_sens = self._post_filter_by_ner(kept_sens)\n",
    "        return simplified_sens\n",
    "    \n",
    "    def _post_filter_by_len(self, sens):\n",
    "        kept_sens = [sen for sen in sens if len(sen) >= self.post_min_len]\n",
    "        return kept_sens\n",
    "    \n",
    "    def _post_filter_by_ner(self, sens):\n",
    "        # 未实现\n",
    "        return sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = CoreServerAnalyzer()\n",
    "ann = CoreServerAnn(text)\n",
    "ann = analyzer(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CoreServerSen at 0x2a2f05c7358>,\n",
       " <__main__.CoreServerSen at 0x2a2f05c72b0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05c72e8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.source_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = \"IP<(NP=np $..(VP=vp ?$.. PU)) >(ROOT|IP|CP)\"\n",
    "# rule = \"ROOT < (IP<(NP=np $.. VP=vp))\"\n",
    "tranformer = CoreServerTranformer(rule = rule)\n",
    "ann = tranformer(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CoreServerAnn"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens[0].comefrom.comefrom.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CoreServerSen at 0x2a2f05c79b0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05c7da0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05c79e8>,\n",
       " <__main__.CoreServerSen at 0x2a2f05eb1d0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05eba58>,\n",
       " <__main__.CoreServerSen at 0x2a2f05eb0f0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05ebd30>,\n",
       " <__main__.CoreServerSen at 0x2a2f05f7710>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "何洛洛在群访中回应称自己一定是会去高考的\n",
      "自己一定是会去高考\n",
      "今年错过了\n",
      "何洛洛坦言每个人在追梦的道路上都有自己的选择和机会\n",
      "他会对自己的选择全力以赴坚持到底\n",
      "至于错过今年高考是否遗憾，何洛洛给出了否定的答案\n",
      "每个人都有自己的选择\n",
      "既然选择了《创造营2019》，那我明年继续备战高考\n"
     ]
    }
   ],
   "source": [
    "for tmp_sen in ann.derived_sens:\n",
    "    print(tmp_sen.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ann.derived_sens[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'何洛洛在群访中回应称自己一定是会去高考的，虽然今年错过了，但明年一定会全力以赴。'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.source_sens[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'docTokenBegin': 6,\n",
       "  'docTokenEnd': 7,\n",
       "  'tokenBegin': 6,\n",
       "  'tokenEnd': 7,\n",
       "  'text': '2019',\n",
       "  'characterOffsetBegin': 9,\n",
       "  'characterOffsetEnd': 13,\n",
       "  'ner': 'MISC'},\n",
       " {'docTokenBegin': 11,\n",
       "  'docTokenEnd': 12,\n",
       "  'tokenBegin': 11,\n",
       "  'tokenEnd': 12,\n",
       "  'text': '明年',\n",
       "  'characterOffsetBegin': 17,\n",
       "  'characterOffsetEnd': 19,\n",
       "  'ner': 'DATE',\n",
       "  'normalizedNER': 'XXXX-XX-XX'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens[7].sen_dict[\"entitymentions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_str = '(IP\\r\\n  (NP (NN 公民))\\r\\n  (VP\\r\\n    (VP\\r\\n      (VP (VV 申请)\\r\\n        (NP\\r\\n          (ADJP (JJ 普通))\\r\\n          (NP (NN 护照))))\\r\\n      (PU ，)\\r\\n      (VP (VV 应当)\\r\\n        (VP\\r\\n          (PP (P 由)\\r\\n            (NP (PN 本人)))\\r\\n          (PP (P 向)\\r\\n            (NP (PN 其) (NN 户籍)))\\r\\n          (VP (VV 所在)\\r\\n            (NP\\r\\n              (LCP\\r\\n                (NP (NN 地县级))\\r\\n                (LC 以上))\\r\\n              (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构)))\\r\\n            (IP\\r\\n              (VP (VV 提出)))))))\\r\\n    (PU ，)\\r\\n    (CC 并)\\r\\n    (VP (VV 提交)\\r\\n      (NP\\r\\n        (LCP (LC 以上))\\r\\n        (CP\\r\\n          (IP\\r\\n            (VP\\r\\n              (VCD (VA 真实) (VA 有效))))\\r\\n          (DEC 的))\\r\\n        (NP (NN 材料))))))\\r\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(IP\n",
      "  (NP (NN 公民))\n",
      "  (VP\n",
      "    (VP\n",
      "      (VP (VV 申请)\n",
      "        (NP\n",
      "          (ADJP (JJ 普通))\n",
      "          (NP (NN 护照))))\n",
      "      (PU ，)\n",
      "      (VP (VV 应当)\n",
      "        (VP\n",
      "          (PP (P 由)\n",
      "            (NP (PN 本人)))\n",
      "          (PP (P 向)\n",
      "            (NP (PN 其) (NN 户籍)))\n",
      "          (VP (VV 所在)\n",
      "            (NP\n",
      "              (LCP\n",
      "                (NP (NN 地县级))\n",
      "                (LC 以上))\n",
      "              (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构)))\n",
      "            (IP\n",
      "              (VP (VV 提出)))))))\n",
      "    (PU ，)\n",
      "    (CC 并)\n",
      "    (VP (VV 提交)\n",
      "      (NP\n",
      "        (LCP (LC 以上))\n",
      "        (CP\n",
      "          (IP\n",
      "            (VP\n",
      "              (VCD (VA 真实) (VA 有效))))\n",
      "          (DEC 的))\n",
      "        (NP (NN 材料))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree_str = re.sub('\\s+', ' ', tree_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(IP\\r\\n  (NP (NN 公民))\\r\\n  (VP\\r\\n    (VP\\r\\n      (VP (VV 申请)\\r\\n        (NP\\r\\n          (ADJP (JJ 普通))\\r\\n          (NP (NN 护照))))\\r\\n      (PU ，)\\r\\n      (VP (VV 应当)\\r\\n        (VP\\r\\n          (PP (P 由)\\r\\n            (NP (PN 本人)))\\r\\n          (PP (P 向)\\r\\n            (NP (PN 其) (NN 户籍)))\\r\\n          (VP (VV 所在)\\r\\n            (NP\\r\\n              (LCP\\r\\n                (NP (NN 地县级))\\r\\n                (LC 以上))\\r\\n              (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构)))\\r\\n            (IP\\r\\n              (VP (VV 提出)))))))\\r\\n    (PU ，)\\r\\n    (CC 并)\\r\\n    (VP (VV 提交)\\r\\n      (NP\\r\\n        (LCP (LC 以上))\\r\\n        (CP\\r\\n          (IP\\r\\n            (VP\\r\\n              (VCD (VA 真实) (VA 有效))))\\r\\n          (DEC 的))\\r\\n        (NP (NN 材料))))))\\r\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = re.findall(r'[^\\(\\s\\)]+\\)', '(IP (NP (NN 公民)) (VP (VP (VP (VV 申请) (NP (ADJP (JJ 普通)) (NP (NN 护照)))) (PU ，) (VP (VV 应当) (VP (PP (P 由) (NP (PN 本人))) (PP (P 向) (NP (PN 其) (NN 户籍))) (VP (VV 所在) (NP (LCP (NP (NN 地县级)) (LC 以上)) (NP (NN 地方) (NN 人民) (NN 政府) (NN 公安) (NN 机关) (NN 出入境) (NN 管理) (NN 机构))) (IP (VP (VV 提出))))))) (PU ，) (CC 并) (VP (VV 提交) (NP (LCP (LC 以上)) (CP (IP (VP (VCD (VA 真实) (VA 有效)))) (DEC 的)) (NP (NN 材料)))))) ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['公民)',\n",
       " '申请)',\n",
       " '普通)',\n",
       " '护照)',\n",
       " '，)',\n",
       " '应当)',\n",
       " '由)',\n",
       " '本人)',\n",
       " '向)',\n",
       " '其)',\n",
       " '户籍)',\n",
       " '所在)',\n",
       " '地县级)',\n",
       " '以上)',\n",
       " '地方)',\n",
       " '人民)',\n",
       " '政府)',\n",
       " '公安)',\n",
       " '机关)',\n",
       " '出入境)',\n",
       " '管理)',\n",
       " '机构)',\n",
       " '提出)',\n",
       " '，)',\n",
       " '并)',\n",
       " '提交)',\n",
       " '以上)',\n",
       " '真实)',\n",
       " '有效)',\n",
       " '的)',\n",
       " '材料)']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "for k, v in a.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '何洛洛在群访中回应称自己一定是会去高考的，虽然今年错过了，但明年一定会全力以赴。何洛洛坦言每个人在追梦的道路上都有自己的选择和机会，他会对自己的选择全力以赴坚持到底。至于错过今年高考是否遗憾，何洛洛给出了否定的答案，“每个人都有自己的选择，既然选择了《创造营2019》，那我明年继续备战高考。”',\n",
       " 'source_sens': [<__main__.CoreServerSen at 0x2a2f05c7358>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05c72b0>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05c72e8>],\n",
       " 'derived_sens': [<__main__.CoreServerSen at 0x2a2f05c79b0>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05c7da0>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05c79e8>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05eb1d0>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05eba58>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05eb0f0>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05ebd30>,\n",
       "  <__main__.CoreServerSen at 0x2a2f05f7710>],\n",
       " 'comefrom': None}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sen_dict': {'index': 0,\n",
       "  'entitymentions': [{'docTokenBegin': 0,\n",
       "    'docTokenEnd': 1,\n",
       "    'tokenBegin': 0,\n",
       "    'tokenEnd': 1,\n",
       "    'text': '何洛洛',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 3,\n",
       "    'ner': 'PERSON'}],\n",
       "  'tokens': [{'index': 1,\n",
       "    'word': '何洛洛',\n",
       "    'originalText': '何洛洛',\n",
       "    'lemma': '何洛洛',\n",
       "    'characterOffsetBegin': 0,\n",
       "    'characterOffsetEnd': 3,\n",
       "    'pos': 'NR',\n",
       "    'ner': 'PERSON'},\n",
       "   {'index': 2,\n",
       "    'word': '在',\n",
       "    'originalText': '在',\n",
       "    'lemma': '在',\n",
       "    'characterOffsetBegin': 3,\n",
       "    'characterOffsetEnd': 4,\n",
       "    'pos': 'P',\n",
       "    'ner': 'O'},\n",
       "   {'index': 3,\n",
       "    'word': '群访',\n",
       "    'originalText': '群访',\n",
       "    'lemma': '群访',\n",
       "    'characterOffsetBegin': 4,\n",
       "    'characterOffsetEnd': 6,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 4,\n",
       "    'word': '中',\n",
       "    'originalText': '中',\n",
       "    'lemma': '中',\n",
       "    'characterOffsetBegin': 6,\n",
       "    'characterOffsetEnd': 7,\n",
       "    'pos': 'LC',\n",
       "    'ner': 'O'},\n",
       "   {'index': 5,\n",
       "    'word': '回应',\n",
       "    'originalText': '回应',\n",
       "    'lemma': '回应',\n",
       "    'characterOffsetBegin': 7,\n",
       "    'characterOffsetEnd': 9,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 6,\n",
       "    'word': '称',\n",
       "    'originalText': '称',\n",
       "    'lemma': '称',\n",
       "    'characterOffsetBegin': 9,\n",
       "    'characterOffsetEnd': 10,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 7,\n",
       "    'word': '自己',\n",
       "    'originalText': '自己',\n",
       "    'lemma': '自己',\n",
       "    'characterOffsetBegin': 10,\n",
       "    'characterOffsetEnd': 12,\n",
       "    'pos': 'PN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 8,\n",
       "    'word': '一定',\n",
       "    'originalText': '一定',\n",
       "    'lemma': '一定',\n",
       "    'characterOffsetBegin': 12,\n",
       "    'characterOffsetEnd': 14,\n",
       "    'pos': 'AD',\n",
       "    'ner': 'O'},\n",
       "   {'index': 9,\n",
       "    'word': '是',\n",
       "    'originalText': '是',\n",
       "    'lemma': '是',\n",
       "    'characterOffsetBegin': 14,\n",
       "    'characterOffsetEnd': 15,\n",
       "    'pos': 'VC',\n",
       "    'ner': 'O'},\n",
       "   {'index': 10,\n",
       "    'word': '会',\n",
       "    'originalText': '会',\n",
       "    'lemma': '会',\n",
       "    'characterOffsetBegin': 15,\n",
       "    'characterOffsetEnd': 16,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 11,\n",
       "    'word': '去',\n",
       "    'originalText': '去',\n",
       "    'lemma': '去',\n",
       "    'characterOffsetBegin': 16,\n",
       "    'characterOffsetEnd': 17,\n",
       "    'pos': 'VV',\n",
       "    'ner': 'O'},\n",
       "   {'index': 12,\n",
       "    'word': '高考',\n",
       "    'originalText': '高考',\n",
       "    'lemma': '高考',\n",
       "    'characterOffsetBegin': 17,\n",
       "    'characterOffsetEnd': 19,\n",
       "    'pos': 'NN',\n",
       "    'ner': 'O'},\n",
       "   {'index': 13,\n",
       "    'word': '的',\n",
       "    'originalText': '的',\n",
       "    'lemma': '的',\n",
       "    'characterOffsetBegin': 19,\n",
       "    'characterOffsetEnd': 20,\n",
       "    'pos': 'SP',\n",
       "    'ner': 'O'}]},\n",
       " 'tokens': [{'index': 1,\n",
       "   'word': '何洛洛',\n",
       "   'originalText': '何洛洛',\n",
       "   'lemma': '何洛洛',\n",
       "   'characterOffsetBegin': 0,\n",
       "   'characterOffsetEnd': 3,\n",
       "   'pos': 'NR',\n",
       "   'ner': 'PERSON'},\n",
       "  {'index': 2,\n",
       "   'word': '在',\n",
       "   'originalText': '在',\n",
       "   'lemma': '在',\n",
       "   'characterOffsetBegin': 3,\n",
       "   'characterOffsetEnd': 4,\n",
       "   'pos': 'P',\n",
       "   'ner': 'O'},\n",
       "  {'index': 3,\n",
       "   'word': '群访',\n",
       "   'originalText': '群访',\n",
       "   'lemma': '群访',\n",
       "   'characterOffsetBegin': 4,\n",
       "   'characterOffsetEnd': 6,\n",
       "   'pos': 'NN',\n",
       "   'ner': 'O'},\n",
       "  {'index': 4,\n",
       "   'word': '中',\n",
       "   'originalText': '中',\n",
       "   'lemma': '中',\n",
       "   'characterOffsetBegin': 6,\n",
       "   'characterOffsetEnd': 7,\n",
       "   'pos': 'LC',\n",
       "   'ner': 'O'},\n",
       "  {'index': 5,\n",
       "   'word': '回应',\n",
       "   'originalText': '回应',\n",
       "   'lemma': '回应',\n",
       "   'characterOffsetBegin': 7,\n",
       "   'characterOffsetEnd': 9,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 6,\n",
       "   'word': '称',\n",
       "   'originalText': '称',\n",
       "   'lemma': '称',\n",
       "   'characterOffsetBegin': 9,\n",
       "   'characterOffsetEnd': 10,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 7,\n",
       "   'word': '自己',\n",
       "   'originalText': '自己',\n",
       "   'lemma': '自己',\n",
       "   'characterOffsetBegin': 10,\n",
       "   'characterOffsetEnd': 12,\n",
       "   'pos': 'PN',\n",
       "   'ner': 'O'},\n",
       "  {'index': 8,\n",
       "   'word': '一定',\n",
       "   'originalText': '一定',\n",
       "   'lemma': '一定',\n",
       "   'characterOffsetBegin': 12,\n",
       "   'characterOffsetEnd': 14,\n",
       "   'pos': 'AD',\n",
       "   'ner': 'O'},\n",
       "  {'index': 9,\n",
       "   'word': '是',\n",
       "   'originalText': '是',\n",
       "   'lemma': '是',\n",
       "   'characterOffsetBegin': 14,\n",
       "   'characterOffsetEnd': 15,\n",
       "   'pos': 'VC',\n",
       "   'ner': 'O'},\n",
       "  {'index': 10,\n",
       "   'word': '会',\n",
       "   'originalText': '会',\n",
       "   'lemma': '会',\n",
       "   'characterOffsetBegin': 15,\n",
       "   'characterOffsetEnd': 16,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 11,\n",
       "   'word': '去',\n",
       "   'originalText': '去',\n",
       "   'lemma': '去',\n",
       "   'characterOffsetBegin': 16,\n",
       "   'characterOffsetEnd': 17,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 12,\n",
       "   'word': '高考',\n",
       "   'originalText': '高考',\n",
       "   'lemma': '高考',\n",
       "   'characterOffsetBegin': 17,\n",
       "   'characterOffsetEnd': 19,\n",
       "   'pos': 'NN',\n",
       "   'ner': 'O'},\n",
       "  {'index': 13,\n",
       "   'word': '的',\n",
       "   'originalText': '的',\n",
       "   'lemma': '的',\n",
       "   'characterOffsetBegin': 19,\n",
       "   'characterOffsetEnd': 20,\n",
       "   'pos': 'SP',\n",
       "   'ner': 'O'}],\n",
       " 'words': ['何洛洛',\n",
       "  '在',\n",
       "  '群访',\n",
       "  '中',\n",
       "  '回应',\n",
       "  '称',\n",
       "  '自己',\n",
       "  '一定',\n",
       "  '是',\n",
       "  '会',\n",
       "  '去',\n",
       "  '高考',\n",
       "  '的'],\n",
       " 'text': '何洛洛在群访中回应称自己一定是会去高考的',\n",
       " 'comefrom': <__main__.CoreServerSen at 0x2a2f05c7358>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreServerTransducer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, ann):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "transducer = CoreServerTransducer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CoreServerSen at 0x2a2f05c79b0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05c7da0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05c79e8>,\n",
       " <__main__.CoreServerSen at 0x2a2f05eb1d0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05eba58>,\n",
       " <__main__.CoreServerSen at 0x2a2f05eb0f0>,\n",
       " <__main__.CoreServerSen at 0x2a2f05ebd30>,\n",
       " <__main__.CoreServerSen at 0x2a2f05f7710>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'何洛洛在群访中回应称自己一定是会去高考的'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'自己一定是会去高考'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens[1].sen_dict[\"entitymentions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'entitymentions': [{'docTokenBegin': 0,\n",
       "   'docTokenEnd': 1,\n",
       "   'tokenBegin': 0,\n",
       "   'tokenEnd': 1,\n",
       "   'text': '何洛洛',\n",
       "   'characterOffsetBegin': 0,\n",
       "   'characterOffsetEnd': 3,\n",
       "   'ner': 'PERSON'},\n",
       "  {'docTokenBegin': 15,\n",
       "   'docTokenEnd': 16,\n",
       "   'tokenBegin': 15,\n",
       "   'tokenEnd': 16,\n",
       "   'text': '今年',\n",
       "   'characterOffsetBegin': 23,\n",
       "   'characterOffsetEnd': 25,\n",
       "   'ner': 'DATE',\n",
       "   'normalizedNER': 'XXXX-XX-XX'},\n",
       "  {'docTokenBegin': 20,\n",
       "   'docTokenEnd': 21,\n",
       "   'tokenBegin': 20,\n",
       "   'tokenEnd': 21,\n",
       "   'text': '明年',\n",
       "   'characterOffsetBegin': 30,\n",
       "   'characterOffsetEnd': 32,\n",
       "   'ner': 'DATE',\n",
       "   'normalizedNER': 'XXXX-XX-XX'}],\n",
       " 'tokens': [{'index': 1,\n",
       "   'word': '何洛洛',\n",
       "   'originalText': '何洛洛',\n",
       "   'lemma': '何洛洛',\n",
       "   'characterOffsetBegin': 0,\n",
       "   'characterOffsetEnd': 3,\n",
       "   'pos': 'NR',\n",
       "   'ner': 'PERSON'},\n",
       "  {'index': 2,\n",
       "   'word': '在',\n",
       "   'originalText': '在',\n",
       "   'lemma': '在',\n",
       "   'characterOffsetBegin': 3,\n",
       "   'characterOffsetEnd': 4,\n",
       "   'pos': 'P',\n",
       "   'ner': 'O'},\n",
       "  {'index': 3,\n",
       "   'word': '群访',\n",
       "   'originalText': '群访',\n",
       "   'lemma': '群访',\n",
       "   'characterOffsetBegin': 4,\n",
       "   'characterOffsetEnd': 6,\n",
       "   'pos': 'NN',\n",
       "   'ner': 'O'},\n",
       "  {'index': 4,\n",
       "   'word': '中',\n",
       "   'originalText': '中',\n",
       "   'lemma': '中',\n",
       "   'characterOffsetBegin': 6,\n",
       "   'characterOffsetEnd': 7,\n",
       "   'pos': 'LC',\n",
       "   'ner': 'O'},\n",
       "  {'index': 5,\n",
       "   'word': '回应',\n",
       "   'originalText': '回应',\n",
       "   'lemma': '回应',\n",
       "   'characterOffsetBegin': 7,\n",
       "   'characterOffsetEnd': 9,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 6,\n",
       "   'word': '称',\n",
       "   'originalText': '称',\n",
       "   'lemma': '称',\n",
       "   'characterOffsetBegin': 9,\n",
       "   'characterOffsetEnd': 10,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 7,\n",
       "   'word': '自己',\n",
       "   'originalText': '自己',\n",
       "   'lemma': '自己',\n",
       "   'characterOffsetBegin': 10,\n",
       "   'characterOffsetEnd': 12,\n",
       "   'pos': 'PN',\n",
       "   'ner': 'O'},\n",
       "  {'index': 8,\n",
       "   'word': '一定',\n",
       "   'originalText': '一定',\n",
       "   'lemma': '一定',\n",
       "   'characterOffsetBegin': 12,\n",
       "   'characterOffsetEnd': 14,\n",
       "   'pos': 'AD',\n",
       "   'ner': 'O'},\n",
       "  {'index': 9,\n",
       "   'word': '是',\n",
       "   'originalText': '是',\n",
       "   'lemma': '是',\n",
       "   'characterOffsetBegin': 14,\n",
       "   'characterOffsetEnd': 15,\n",
       "   'pos': 'VC',\n",
       "   'ner': 'O'},\n",
       "  {'index': 10,\n",
       "   'word': '会',\n",
       "   'originalText': '会',\n",
       "   'lemma': '会',\n",
       "   'characterOffsetBegin': 15,\n",
       "   'characterOffsetEnd': 16,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 11,\n",
       "   'word': '去',\n",
       "   'originalText': '去',\n",
       "   'lemma': '去',\n",
       "   'characterOffsetBegin': 16,\n",
       "   'characterOffsetEnd': 17,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 12,\n",
       "   'word': '高考',\n",
       "   'originalText': '高考',\n",
       "   'lemma': '高考',\n",
       "   'characterOffsetBegin': 17,\n",
       "   'characterOffsetEnd': 19,\n",
       "   'pos': 'NN',\n",
       "   'ner': 'O'},\n",
       "  {'index': 13,\n",
       "   'word': '的',\n",
       "   'originalText': '的',\n",
       "   'lemma': '的',\n",
       "   'characterOffsetBegin': 19,\n",
       "   'characterOffsetEnd': 20,\n",
       "   'pos': 'SP',\n",
       "   'ner': 'O'},\n",
       "  {'index': 14,\n",
       "   'word': '，',\n",
       "   'originalText': '，',\n",
       "   'lemma': '，',\n",
       "   'characterOffsetBegin': 20,\n",
       "   'characterOffsetEnd': 21,\n",
       "   'pos': 'PU',\n",
       "   'ner': 'O'},\n",
       "  {'index': 15,\n",
       "   'word': '虽然',\n",
       "   'originalText': '虽然',\n",
       "   'lemma': '虽然',\n",
       "   'characterOffsetBegin': 21,\n",
       "   'characterOffsetEnd': 23,\n",
       "   'pos': 'CS',\n",
       "   'ner': 'O'},\n",
       "  {'index': 16,\n",
       "   'word': '今年',\n",
       "   'originalText': '今年',\n",
       "   'lemma': '今年',\n",
       "   'characterOffsetBegin': 23,\n",
       "   'characterOffsetEnd': 25,\n",
       "   'pos': 'NT',\n",
       "   'ner': 'DATE',\n",
       "   'normalizedNER': 'XXXX-XX-XX'},\n",
       "  {'index': 17,\n",
       "   'word': '错过',\n",
       "   'originalText': '错过',\n",
       "   'lemma': '错过',\n",
       "   'characterOffsetBegin': 25,\n",
       "   'characterOffsetEnd': 27,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 18,\n",
       "   'word': '了',\n",
       "   'originalText': '了',\n",
       "   'lemma': '了',\n",
       "   'characterOffsetBegin': 27,\n",
       "   'characterOffsetEnd': 28,\n",
       "   'pos': 'AS',\n",
       "   'ner': 'O'},\n",
       "  {'index': 19,\n",
       "   'word': '，',\n",
       "   'originalText': '，',\n",
       "   'lemma': '，',\n",
       "   'characterOffsetBegin': 28,\n",
       "   'characterOffsetEnd': 29,\n",
       "   'pos': 'PU',\n",
       "   'ner': 'O'},\n",
       "  {'index': 20,\n",
       "   'word': '但',\n",
       "   'originalText': '但',\n",
       "   'lemma': '但',\n",
       "   'characterOffsetBegin': 29,\n",
       "   'characterOffsetEnd': 30,\n",
       "   'pos': 'AD',\n",
       "   'ner': 'O'},\n",
       "  {'index': 21,\n",
       "   'word': '明年',\n",
       "   'originalText': '明年',\n",
       "   'lemma': '明年',\n",
       "   'characterOffsetBegin': 30,\n",
       "   'characterOffsetEnd': 32,\n",
       "   'pos': 'NT',\n",
       "   'ner': 'DATE',\n",
       "   'normalizedNER': 'XXXX-XX-XX'},\n",
       "  {'index': 22,\n",
       "   'word': '一定',\n",
       "   'originalText': '一定',\n",
       "   'lemma': '一定',\n",
       "   'characterOffsetBegin': 32,\n",
       "   'characterOffsetEnd': 34,\n",
       "   'pos': 'AD',\n",
       "   'ner': 'O'},\n",
       "  {'index': 23,\n",
       "   'word': '会',\n",
       "   'originalText': '会',\n",
       "   'lemma': '会',\n",
       "   'characterOffsetBegin': 34,\n",
       "   'characterOffsetEnd': 35,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 24,\n",
       "   'word': '全力以赴',\n",
       "   'originalText': '全力以赴',\n",
       "   'lemma': '全力以赴',\n",
       "   'characterOffsetBegin': 35,\n",
       "   'characterOffsetEnd': 39,\n",
       "   'pos': 'VV',\n",
       "   'ner': 'O'},\n",
       "  {'index': 25,\n",
       "   'word': '。',\n",
       "   'originalText': '。',\n",
       "   'lemma': '。',\n",
       "   'characterOffsetBegin': 39,\n",
       "   'characterOffsetEnd': 40,\n",
       "   'pos': 'PU',\n",
       "   'ner': 'O'}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.source_sens[0].sen_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = {\"annotators\": \"tokenize,ssplit,pos,ner,parse\",\n",
    "              \"ssplit.boundaryTokenRegex\": \"[.。]|[!?！？]\",\n",
    "              \"pipelineLanguage\": \"zh\"\n",
    "             }\n",
    "tmp = requests.post(\"http://localhost:9000\", data= \"既然选择了《创造营2019》，那我明年继续备战高考\".encode('utf8'), params = {\"properties\": str(properties)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentences': [{'index': 0,\n",
       "   'parse': '(ROOT\\r\\n  (IP\\r\\n    (CP\\r\\n      (ADVP (CS 既然))\\r\\n      (IP\\r\\n        (VP (VV 选择) (AS 了)\\r\\n          (IP\\r\\n            (NP (PU 《))\\r\\n            (VP (VV 创造)\\r\\n              (NP (NN 营) (NN 2019)))\\r\\n            (PU 》)))))\\r\\n    (PU ，)\\r\\n    (ADVP (AD 那))\\r\\n    (NP (PN 我))\\r\\n    (VP\\r\\n      (NP (NT 明年))\\r\\n      (VP (VV 继续)\\r\\n        (VP (VV 备战)\\r\\n          (NP (NN 高考)))))))',\n",
       "   'basicDependencies': [{'dep': 'ROOT',\n",
       "     'governor': 0,\n",
       "     'governorGloss': 'ROOT',\n",
       "     'dependent': 14,\n",
       "     'dependentGloss': '备战'},\n",
       "    {'dep': 'advmod',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 1,\n",
       "     'dependentGloss': '既然'},\n",
       "    {'dep': 'dep',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 2,\n",
       "     'dependentGloss': '选择'},\n",
       "    {'dep': 'aux:asp',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 3,\n",
       "     'dependentGloss': '了'},\n",
       "    {'dep': 'nsubj',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 4,\n",
       "     'dependentGloss': '《'},\n",
       "    {'dep': 'ccomp',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 5,\n",
       "     'dependentGloss': '创造'},\n",
       "    {'dep': 'compound:nn',\n",
       "     'governor': 7,\n",
       "     'governorGloss': '2019',\n",
       "     'dependent': 6,\n",
       "     'dependentGloss': '营'},\n",
       "    {'dep': 'dobj',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 7,\n",
       "     'dependentGloss': '2019'},\n",
       "    {'dep': 'punct',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 8,\n",
       "     'dependentGloss': '》'},\n",
       "    {'dep': 'punct',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 9,\n",
       "     'dependentGloss': '，'},\n",
       "    {'dep': 'advmod',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 10,\n",
       "     'dependentGloss': '那'},\n",
       "    {'dep': 'nsubj',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 11,\n",
       "     'dependentGloss': '我'},\n",
       "    {'dep': 'nmod:tmod',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 12,\n",
       "     'dependentGloss': '明年'},\n",
       "    {'dep': 'xcomp',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 13,\n",
       "     'dependentGloss': '继续'},\n",
       "    {'dep': 'dobj',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 15,\n",
       "     'dependentGloss': '高考'}],\n",
       "   'enhancedDependencies': [{'dep': 'ROOT',\n",
       "     'governor': 0,\n",
       "     'governorGloss': 'ROOT',\n",
       "     'dependent': 14,\n",
       "     'dependentGloss': '备战'},\n",
       "    {'dep': 'advmod',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 1,\n",
       "     'dependentGloss': '既然'},\n",
       "    {'dep': 'dep',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 2,\n",
       "     'dependentGloss': '选择'},\n",
       "    {'dep': 'aux:asp',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 3,\n",
       "     'dependentGloss': '了'},\n",
       "    {'dep': 'nsubj',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 4,\n",
       "     'dependentGloss': '《'},\n",
       "    {'dep': 'ccomp',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 5,\n",
       "     'dependentGloss': '创造'},\n",
       "    {'dep': 'compound:nn',\n",
       "     'governor': 7,\n",
       "     'governorGloss': '2019',\n",
       "     'dependent': 6,\n",
       "     'dependentGloss': '营'},\n",
       "    {'dep': 'dobj',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 7,\n",
       "     'dependentGloss': '2019'},\n",
       "    {'dep': 'punct',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 8,\n",
       "     'dependentGloss': '》'},\n",
       "    {'dep': 'punct',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 9,\n",
       "     'dependentGloss': '，'},\n",
       "    {'dep': 'advmod',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 10,\n",
       "     'dependentGloss': '那'},\n",
       "    {'dep': 'nsubj',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 11,\n",
       "     'dependentGloss': '我'},\n",
       "    {'dep': 'nmod:tmod',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 12,\n",
       "     'dependentGloss': '明年'},\n",
       "    {'dep': 'xcomp',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 13,\n",
       "     'dependentGloss': '继续'},\n",
       "    {'dep': 'dobj',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 15,\n",
       "     'dependentGloss': '高考'}],\n",
       "   'enhancedPlusPlusDependencies': [{'dep': 'ROOT',\n",
       "     'governor': 0,\n",
       "     'governorGloss': 'ROOT',\n",
       "     'dependent': 14,\n",
       "     'dependentGloss': '备战'},\n",
       "    {'dep': 'advmod',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 1,\n",
       "     'dependentGloss': '既然'},\n",
       "    {'dep': 'dep',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 2,\n",
       "     'dependentGloss': '选择'},\n",
       "    {'dep': 'aux:asp',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 3,\n",
       "     'dependentGloss': '了'},\n",
       "    {'dep': 'nsubj',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 4,\n",
       "     'dependentGloss': '《'},\n",
       "    {'dep': 'ccomp',\n",
       "     'governor': 2,\n",
       "     'governorGloss': '选择',\n",
       "     'dependent': 5,\n",
       "     'dependentGloss': '创造'},\n",
       "    {'dep': 'compound:nn',\n",
       "     'governor': 7,\n",
       "     'governorGloss': '2019',\n",
       "     'dependent': 6,\n",
       "     'dependentGloss': '营'},\n",
       "    {'dep': 'dobj',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 7,\n",
       "     'dependentGloss': '2019'},\n",
       "    {'dep': 'punct',\n",
       "     'governor': 5,\n",
       "     'governorGloss': '创造',\n",
       "     'dependent': 8,\n",
       "     'dependentGloss': '》'},\n",
       "    {'dep': 'punct',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 9,\n",
       "     'dependentGloss': '，'},\n",
       "    {'dep': 'advmod',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 10,\n",
       "     'dependentGloss': '那'},\n",
       "    {'dep': 'nsubj',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 11,\n",
       "     'dependentGloss': '我'},\n",
       "    {'dep': 'nmod:tmod',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 12,\n",
       "     'dependentGloss': '明年'},\n",
       "    {'dep': 'xcomp',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 13,\n",
       "     'dependentGloss': '继续'},\n",
       "    {'dep': 'dobj',\n",
       "     'governor': 14,\n",
       "     'governorGloss': '备战',\n",
       "     'dependent': 15,\n",
       "     'dependentGloss': '高考'}],\n",
       "   'entitymentions': [{'docTokenBegin': 6,\n",
       "     'docTokenEnd': 7,\n",
       "     'tokenBegin': 6,\n",
       "     'tokenEnd': 7,\n",
       "     'text': '2019',\n",
       "     'characterOffsetBegin': 9,\n",
       "     'characterOffsetEnd': 13,\n",
       "     'ner': 'MISC'},\n",
       "    {'docTokenBegin': 11,\n",
       "     'docTokenEnd': 12,\n",
       "     'tokenBegin': 11,\n",
       "     'tokenEnd': 12,\n",
       "     'text': '明年',\n",
       "     'characterOffsetBegin': 17,\n",
       "     'characterOffsetEnd': 19,\n",
       "     'ner': 'DATE',\n",
       "     'normalizedNER': 'XXXX-XX-XX'}],\n",
       "   'tokens': [{'index': 1,\n",
       "     'word': '既然',\n",
       "     'originalText': '既然',\n",
       "     'lemma': '既然',\n",
       "     'characterOffsetBegin': 0,\n",
       "     'characterOffsetEnd': 2,\n",
       "     'pos': 'CS',\n",
       "     'ner': 'O'},\n",
       "    {'index': 2,\n",
       "     'word': '选择',\n",
       "     'originalText': '选择',\n",
       "     'lemma': '选择',\n",
       "     'characterOffsetBegin': 2,\n",
       "     'characterOffsetEnd': 4,\n",
       "     'pos': 'VV',\n",
       "     'ner': 'O'},\n",
       "    {'index': 3,\n",
       "     'word': '了',\n",
       "     'originalText': '了',\n",
       "     'lemma': '了',\n",
       "     'characterOffsetBegin': 4,\n",
       "     'characterOffsetEnd': 5,\n",
       "     'pos': 'AS',\n",
       "     'ner': 'O'},\n",
       "    {'index': 4,\n",
       "     'word': '《',\n",
       "     'originalText': '《',\n",
       "     'lemma': '《',\n",
       "     'characterOffsetBegin': 5,\n",
       "     'characterOffsetEnd': 6,\n",
       "     'pos': 'PU',\n",
       "     'ner': 'O'},\n",
       "    {'index': 5,\n",
       "     'word': '创造',\n",
       "     'originalText': '创造',\n",
       "     'lemma': '创造',\n",
       "     'characterOffsetBegin': 6,\n",
       "     'characterOffsetEnd': 8,\n",
       "     'pos': 'VV',\n",
       "     'ner': 'O'},\n",
       "    {'index': 6,\n",
       "     'word': '营',\n",
       "     'originalText': '营',\n",
       "     'lemma': '营',\n",
       "     'characterOffsetBegin': 8,\n",
       "     'characterOffsetEnd': 9,\n",
       "     'pos': 'NN',\n",
       "     'ner': 'O'},\n",
       "    {'index': 7,\n",
       "     'word': '2019',\n",
       "     'originalText': '2019',\n",
       "     'lemma': '2019',\n",
       "     'characterOffsetBegin': 9,\n",
       "     'characterOffsetEnd': 13,\n",
       "     'pos': 'NN',\n",
       "     'ner': 'MISC'},\n",
       "    {'index': 8,\n",
       "     'word': '》',\n",
       "     'originalText': '》',\n",
       "     'lemma': '》',\n",
       "     'characterOffsetBegin': 13,\n",
       "     'characterOffsetEnd': 14,\n",
       "     'pos': 'PU',\n",
       "     'ner': 'O'},\n",
       "    {'index': 9,\n",
       "     'word': '，',\n",
       "     'originalText': '，',\n",
       "     'lemma': '，',\n",
       "     'characterOffsetBegin': 14,\n",
       "     'characterOffsetEnd': 15,\n",
       "     'pos': 'PU',\n",
       "     'ner': 'O'},\n",
       "    {'index': 10,\n",
       "     'word': '那',\n",
       "     'originalText': '那',\n",
       "     'lemma': '那',\n",
       "     'characterOffsetBegin': 15,\n",
       "     'characterOffsetEnd': 16,\n",
       "     'pos': 'AD',\n",
       "     'ner': 'O'},\n",
       "    {'index': 11,\n",
       "     'word': '我',\n",
       "     'originalText': '我',\n",
       "     'lemma': '我',\n",
       "     'characterOffsetBegin': 16,\n",
       "     'characterOffsetEnd': 17,\n",
       "     'pos': 'PN',\n",
       "     'ner': 'O'},\n",
       "    {'index': 12,\n",
       "     'word': '明年',\n",
       "     'originalText': '明年',\n",
       "     'lemma': '明年',\n",
       "     'characterOffsetBegin': 17,\n",
       "     'characterOffsetEnd': 19,\n",
       "     'pos': 'NT',\n",
       "     'ner': 'DATE',\n",
       "     'normalizedNER': 'XXXX-XX-XX'},\n",
       "    {'index': 13,\n",
       "     'word': '继续',\n",
       "     'originalText': '继续',\n",
       "     'lemma': '继续',\n",
       "     'characterOffsetBegin': 19,\n",
       "     'characterOffsetEnd': 21,\n",
       "     'pos': 'VV',\n",
       "     'ner': 'O'},\n",
       "    {'index': 14,\n",
       "     'word': '备战',\n",
       "     'originalText': '备战',\n",
       "     'lemma': '备战',\n",
       "     'characterOffsetBegin': 21,\n",
       "     'characterOffsetEnd': 23,\n",
       "     'pos': 'VV',\n",
       "     'ner': 'O'},\n",
       "    {'index': 15,\n",
       "     'word': '高考',\n",
       "     'originalText': '高考',\n",
       "     'lemma': '高考',\n",
       "     'characterOffsetBegin': 23,\n",
       "     'characterOffsetEnd': 25,\n",
       "     'pos': 'NN',\n",
       "     'ner': 'O'}]}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
