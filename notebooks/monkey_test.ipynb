{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from stanfordnlp.server import CoreNLPClient\n",
    "from stanfordcorenlp import StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoreServerAnn(object):\n",
    "    def __init__(self, text, comefrom = None):\n",
    "        self.text = text\n",
    "        self.source_sens = []\n",
    "        self.derived_sens = []\n",
    "        self.quests = []\n",
    "        self.comefrom = comefrom\n",
    "\n",
    "        \n",
    "class CoreServerQuest(object):\n",
    "    def __init__(self, text, comefrom):\n",
    "        self.text = text\n",
    "        self.comefrom = comefrom\n",
    "        \n",
    "\n",
    "class CoreServerSen(object):\n",
    "    def __init__(self, sen_dict, comefrom = None):\n",
    "        self.sen_dict = sen_dict\n",
    "        self.tokens = self.sen_dict['tokens']\n",
    "        self.words = self._get_words(self.tokens)\n",
    "        self.text = self._get_text(self.tokens)\n",
    "        self.comefrom = comefrom\n",
    "        self.entitymentions = self._get_entitymentions()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sen_dict['tokens'])\n",
    "    \n",
    "    def _get_text(self, tokens):\n",
    "        return \"\".join(token[\"word\"] for token in tokens)\n",
    "    \n",
    "    def _get_words(self, tokens):\n",
    "        return [token[\"word\"] for token in tokens]\n",
    "    \n",
    "    def _get_entitymentions(self):\n",
    "        return self.sen_dict.get('entitymentions', [])\n",
    "\n",
    "        \n",
    "class CoreServerAnalyzer(object):\n",
    "    def __init__(self, url = 'http://localhost:9000',\n",
    "                 properties = None,\n",
    "                 lang = \"zh\",\n",
    "                 timeout = 60\n",
    "                ):\n",
    "        self.url = url\n",
    "        self.timeout = timeout\n",
    "        self.lang = lang\n",
    "        self.timeout = timeout\n",
    "        if properties is None:\n",
    "            properties = {\"annotators\": \"tokenize,ssplit,pos,ner\",\n",
    "                          \"ssplit.boundaryTokenRegex\": \"[.。]|[!?！？]\",\n",
    "                          \"pipelineLanguage\": self.lang,\n",
    "                          \"'ner.applyFineGrained\": False\n",
    "                         }\n",
    "        self.properties = properties\n",
    "    \n",
    "    def __call__(self, ann, comefrom = None):\n",
    "        if comefrom is None:\n",
    "            comefrom = ann\n",
    "        resp = requests.post(self.url, data=ann.text.encode('utf8'), params = {\"properties\": str(self.properties)},\n",
    "                             timeout = self.timeout\n",
    "                            )\n",
    "        ann.source_sens = [CoreServerSen(sen_dict, comefrom) for sen_dict in resp.json()['sentences']]\n",
    "        return ann\n",
    "\n",
    "\n",
    "class CoreServerTranformer(object):\n",
    "    def __init__(self, max_len = None, by_punc = True, rule = None,\n",
    "                 url = \"http://localhost:9000/tregex\", lang = 'zh',\n",
    "                 timeout = 60,\n",
    "                 post_min_len = None,\n",
    "                 post_by_ner = False,\n",
    "                 entity_labels = None\n",
    "                ):\n",
    "        self.max_len = max_len\n",
    "        self.by_punc = by_punc\n",
    "        self.puncs = ['?!？！']\n",
    "        self.rule = rule\n",
    "        self.lang = lang\n",
    "        self.properties = {\"pipelineLanguage\": self.lang}\n",
    "        self.url = url\n",
    "        self.timeout = timeout\n",
    "        self.analyzer = CoreServerAnalyzer()\n",
    "        self.post_min_len = post_min_len\n",
    "        self.post_by_ner = post_by_ner\n",
    "        self.entity_labels = entity_labels\n",
    "        \n",
    "    def __call__(self, ann):\n",
    "        source_sens = ann.source_sens\n",
    "        kept_sens = self._filter(source_sens)\n",
    "        simplified_sens = self._simplify(kept_sens)\n",
    "        derived_sens = self._post_filter(simplified_sens)\n",
    "        ann.derived_sens = derived_sens\n",
    "        return ann\n",
    "        \n",
    "    def _filter(self, source_sens):\n",
    "        kept_sens = source_sens\n",
    "        if self.max_len is not None:\n",
    "            kept_sens = self._filter_by_len(kept_sens)\n",
    "        if self.by_punc:\n",
    "            kept_sens = self._filter_by_punc(kept_sens)\n",
    "        return kept_sens\n",
    "        \n",
    "    def _filter_by_len(self, sens):\n",
    "        kept_sens = [sen for sen in sens if len(sen) <= self.max_len]\n",
    "        return kept_sens\n",
    "    \n",
    "    def _filter_by_punc(self, sens):\n",
    "        kept_sens = [sen for sen in sens if sen.words[-1].strip() not in self.puncs]\n",
    "        return kept_sens\n",
    "    \n",
    "    def _simplify(self, kept_sens):\n",
    "        simplified_sens = []\n",
    "        for sen in kept_sens:\n",
    "            res = requests.post(self.url, data=sen.text.encode(\"utf8\"), params = {\"pattern\": self.rule, \"properties\": str(self.properties)},\n",
    "                                timeout = self.timeout\n",
    "                               )\n",
    "            res_dict = res.json()\n",
    "            sub_sens = res_dict['sentences'][0]\n",
    "            for sub_k, sub_v in sub_sens.items():\n",
    "                    sub_treestr = sub_v[\"match\"]\n",
    "                    sub_text = self._treestr2text(sub_treestr)\n",
    "                    tmp_ann = CoreServerAnn(sub_text)\n",
    "                    tmp_ann = self.analyzer(tmp_ann, sen)\n",
    "                    simplified_sens += tmp_ann.source_sens\n",
    "        return simplified_sens\n",
    "    \n",
    "    def _treestr2text(self, treestr):\n",
    "        pattern = r'[^\\(\\s\\)]+\\)'\n",
    "        words_ = re.findall(pattern, treestr)\n",
    "        words = [w_[:-1] for w_ in words_]\n",
    "        text = \"\".join(words)\n",
    "        return text\n",
    "    \n",
    "    def _post_filter(self, simplified_sens):\n",
    "        kept_sens = simplified_sens\n",
    "        if self.post_min_len is not None:\n",
    "            kept_sens = self._post_filter_by_len(kept_sens)\n",
    "        if self.post_by_ner:\n",
    "            kept_sens = self._post_filter_by_ner(kept_sens)\n",
    "        return kept_sens\n",
    "    \n",
    "    def _post_filter_by_len(self, sens):\n",
    "        kept_sens = [sen for sen in sens if len(sen) >= self.post_min_len]\n",
    "        return kept_sens\n",
    "    \n",
    "    def _post_filter_by_ner(self, sens):\n",
    "        def check_entity(sen):\n",
    "            entitymentions = sen.entitymentions\n",
    "            if entitymentions == []:\n",
    "                return False\n",
    "            \n",
    "            if any(em['ner'] in self.entity_labels for em in entitymentions) == False:\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "        kept_sens = [sen for sen in sens if check_entity(sen)]\n",
    "        return kept_sens\n",
    "    \n",
    "\n",
    "class CoreServerTransducer(object):\n",
    "    def __init__(self, entity2quest):\n",
    "        self.entity2quest = entity2quest\n",
    "\n",
    "    \n",
    "    def __call__(self, ann):\n",
    "        derived_sens = ann.derived_sens\n",
    "        quests = self._gen_quests(derived_sens)\n",
    "        ann.quests = quests\n",
    "        return ann\n",
    "   \n",
    "    def _gen_quests(self, sens):\n",
    "        quests = []\n",
    "        for sen in sens:\n",
    "            qs = self._sen2quests(sen)\n",
    "            quests += qs\n",
    "        return quests\n",
    "    \n",
    "    def _sen2quests(self, sen):\n",
    "        entitymentions = sen.entitymentions\n",
    "        sen_text = sen.text\n",
    "        quests = []\n",
    "        for em in entitymentions:\n",
    "            ner = em['ner']\n",
    "            cb, ce = em['characterOffsetBegin'], em['characterOffsetEnd']\n",
    "            if ner in self.entity2quest:\n",
    "                quest = sen_text[:cb] + self.entity2quest[ner] + sen_text[ce:]\n",
    "                quests.append(CoreServerQuest(quest, sen))\n",
    "        return quests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"公民申请普通护照，应当由本人向其户籍所在地县级以上地方人民政府公安机关出入境管理机构提出，并提交以上真实有效的材料，现役军人按照管理权限履行报批手续后，由本人向所属部队驻地县级以上地方人民政府公安机关出入境管理机构提出。\"\n",
    "# text =  '何洛洛在群访中回应称自己一定是会去高考的，虽然今年错过了，\\\n",
    "# 但明年一定会全力以赴。何洛洛坦言每个人在追梦的道路上都有自己的选择和机会，\\\n",
    "# 他会对自己的选择全力以赴坚持到底。至于错过今年高考是否遗憾，\\\n",
    "# 何洛洛给出了否定的答案，“每个人都有自己的选择，既然选择了《创造营2019》，那我明年继续备战高考。”'\n",
    "\n",
    "# text = \"作为山东人具体一年到头要吃几顿饺子真的没有具体数字，想吃了就调上馅儿包上咱就吃说说我们这儿必须吃饺子的日子：小年吃、大年三十12点钟声一敲必须吃饺子、正月初二送年的时候吃、过冬至的时候吃（俗语是为了防止冻耳朵），有人要远行一定要吃送行的饺子（俗语上车的饺子下车的面）还有嫁女儿一定要吃饺子，俗语叫做“滚蛋饺”（哈哈）\"\n",
    "text = \"马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。在2019年，阿里巴巴集团与上海签订了战略合作协议。\"\n",
    "analyzer = CoreServerAnalyzer()\n",
    "ann = CoreServerAnn(text)\n",
    "ann = analyzer(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CoreServerSen at 0x2b5ccec1be0>,\n",
       " <__main__.CoreServerSen at 0x2b5ccec1c18>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.source_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOCATION', 'PERSON', 'GPE', 'ORGANIZATION']\n"
     ]
    }
   ],
   "source": [
    "rule = \"IP<(NP=np $..(VP=vp ?$.. PU)) >(ROOT|IP|CP)\"\n",
    "# rule = \"ROOT < (IP<(NP=np $.. VP=vp))\"\n",
    "entity2quest = {\"LOCATION\": \"{ 哪里 | 什么地方 }\",\n",
    "                \"PERSON\": \"{ 谁 }\",\n",
    "                \"GPE\": \"{ 哪里 | 什么地方 }\",\n",
    "                \"ORGANIZATION\": \"{ 什么 组织|机构 }\"\n",
    "               }\n",
    "entity_labels = list(entity2quest.keys())\n",
    "print(entity_labels)\n",
    "tranformer = CoreServerTranformer(rule = rule, entity_labels = entity_labels,\n",
    "                                  post_by_ner= True\n",
    "                                 )\n",
    "ann = tranformer(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CoreServerSen at 0x2b5ccf355c0>,\n",
       " <__main__.CoreServerSen at 0x2b5ccf35668>,\n",
       " <__main__.CoreServerSen at 0x2b5cced89e8>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.derived_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "马云是阿里巴巴集团的创始人之一\n",
      "他于十几年前在浙江杭州创办了阿里巴巴集团\n",
      "在2019年，阿里巴巴集团与上海签订了战略合作协议。\n"
     ]
    }
   ],
   "source": [
    "for tmp_sen in ann.derived_sens:\n",
    "    print(tmp_sen.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'docTokenBegin': 0, 'docTokenEnd': 1, 'tokenBegin': 0, 'tokenEnd': 1, 'text': '马云', 'characterOffsetBegin': 0, 'characterOffsetEnd': 2, 'ner': 'PERSON'}, {'docTokenBegin': 2, 'docTokenEnd': 4, 'tokenBegin': 2, 'tokenEnd': 4, 'text': '阿里巴巴集团', 'characterOffsetBegin': 3, 'characterOffsetEnd': 9, 'ner': 'ORGANIZATION'}, {'docTokenBegin': 6, 'docTokenEnd': 7, 'tokenBegin': 6, 'tokenEnd': 7, 'text': '之一', 'characterOffsetBegin': 13, 'characterOffsetEnd': 15, 'ner': 'MISC'}]\n",
      "[{'docTokenBegin': 2, 'docTokenEnd': 3, 'tokenBegin': 2, 'tokenEnd': 3, 'text': '十几', 'characterOffsetBegin': 2, 'characterOffsetEnd': 4, 'ner': 'NUMBER'}, {'docTokenBegin': 3, 'docTokenEnd': 5, 'tokenBegin': 3, 'tokenEnd': 5, 'text': '年前', 'characterOffsetBegin': 4, 'characterOffsetEnd': 6, 'ner': 'MISC'}, {'docTokenBegin': 6, 'docTokenEnd': 7, 'tokenBegin': 6, 'tokenEnd': 7, 'text': '浙江', 'characterOffsetBegin': 7, 'characterOffsetEnd': 9, 'ner': 'STATE_OR_PROVINCE'}, {'docTokenBegin': 7, 'docTokenEnd': 8, 'tokenBegin': 7, 'tokenEnd': 8, 'text': '杭州', 'characterOffsetBegin': 9, 'characterOffsetEnd': 11, 'ner': 'CITY'}, {'docTokenBegin': 10, 'docTokenEnd': 12, 'tokenBegin': 10, 'tokenEnd': 12, 'text': '阿里巴巴集团', 'characterOffsetBegin': 14, 'characterOffsetEnd': 20, 'ner': 'ORGANIZATION'}]\n",
      "[{'docTokenBegin': 1, 'docTokenEnd': 2, 'tokenBegin': 1, 'tokenEnd': 2, 'text': '2019年', 'characterOffsetBegin': 1, 'characterOffsetEnd': 6, 'ner': 'DATE', 'normalizedNER': '2019-XX-XX'}, {'docTokenBegin': 3, 'docTokenEnd': 5, 'tokenBegin': 3, 'tokenEnd': 5, 'text': '阿里巴巴集团', 'characterOffsetBegin': 7, 'characterOffsetEnd': 13, 'ner': 'ORGANIZATION'}, {'docTokenBegin': 6, 'docTokenEnd': 7, 'tokenBegin': 6, 'tokenEnd': 7, 'text': '上海', 'characterOffsetBegin': 14, 'characterOffsetEnd': 16, 'ner': 'STATE_OR_PROVINCE'}]\n"
     ]
    }
   ],
   "source": [
    "for tmp_sen in ann.derived_sens:\n",
    "    print(tmp_sen.entitymentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transducer = CoreServerTransducer(entity2quest)\n",
    "ann = transducer(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.CoreServerQuest at 0x2b5ccf09940>,\n",
       " <__main__.CoreServerQuest at 0x2b5ccf097f0>,\n",
       " <__main__.CoreServerQuest at 0x2b5ccf09668>,\n",
       " <__main__.CoreServerQuest at 0x2b5ccec12b0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.quests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问： { 谁 }是阿里巴巴集团的创始人之一\n",
      "答1： 马云是阿里巴巴集团的创始人之一\n",
      "答2： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。\n",
      "答3： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。在2019年，阿里巴巴集团与上海签订了战略合作协议。\n",
      "\n",
      "\n",
      "问： 马云是{ 什么 组织|机构 }的创始人之一\n",
      "答1： 马云是阿里巴巴集团的创始人之一\n",
      "答2： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。\n",
      "答3： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。在2019年，阿里巴巴集团与上海签订了战略合作协议。\n",
      "\n",
      "\n",
      "问： 他于十几年前在浙江杭州创办了{ 什么 组织|机构 }\n",
      "答1： 他于十几年前在浙江杭州创办了阿里巴巴集团\n",
      "答2： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。\n",
      "答3： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。在2019年，阿里巴巴集团与上海签订了战略合作协议。\n",
      "\n",
      "\n",
      "问： 在2019年，{ 什么 组织|机构 }与上海签订了战略合作协议。\n",
      "答1： 在2019年，阿里巴巴集团与上海签订了战略合作协议。\n",
      "答2： 在2019年，阿里巴巴集团与上海签订了战略合作协议。\n",
      "答3： 马云是阿里巴巴集团的创始人之一，他于十几年前在浙江杭州创办了阿里巴巴集团。在2019年，阿里巴巴集团与上海签订了战略合作协议。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in ann.quests:\n",
    "    print(\"问：\", q.text)\n",
    "    print(\"答1：\", q.comefrom.text)\n",
    "    print(\"答2：\", q.comefrom.comefrom.text)\n",
    "    print(\"答3：\", q.comefrom.comefrom.comefrom.text)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
